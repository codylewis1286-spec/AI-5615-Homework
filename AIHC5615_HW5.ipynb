{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5fe187e",
   "metadata": {},
   "source": [
    "# AIHC 5615 — Homework 5: King County House Prices\n",
    "_Autogenerated on 2025-11-10 17:17:01_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2545f8",
   "metadata": {},
   "source": [
    "\n",
    "This notebook follows the assignment prompts exactly. \n",
    "It uses **pandas**, **numpy**, **matplotlib**, **scipy**, **statsmodels**, and **scikit-learn** (for standardization).\n",
    "Update the `DATA_PATH` cell below to point to your **training** portion of the King County dataset.\n",
    "If you only have the full dataset (e.g., `kc_house_data.csv`), the notebook will create a train/test split and use the **train** set by default.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cefae89",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ==========================\n",
    "# Setup & Data Loading\n",
    "# ==========================\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Show plots inline if in Jupyter\n",
    "# (No special style/colors per your class rules)\n",
    "# %matplotlib inline  # Uncomment if running in classic Jupyter\n",
    "\n",
    "# ---- UPDATE THIS PATH ----\n",
    "# Set this to the CSV file of your dataset (either training set or full dataset).\n",
    "DATA_PATH = r'C:\\Users\\M298134\\Desktop\\AIHC 5615\\Week 1\\data\\kc_house_data.csv'  # <-- change if needed\n",
    "\n",
    "if not os.path.exists(DATA_PATH):\n",
    "    print('WARNING: DATA_PATH does not exist. Update the path to your data file.')\n",
    "else:\n",
    "    print('Found data file at:', DATA_PATH)\n",
    "\n",
    "# Load\n",
    "df_full = pd.read_csv(DATA_PATH)\n",
    "\n",
    "# Typical columns in the King County dataset:\n",
    "# 'price','bedrooms','bathrooms','sqft_living','sqft_lot','floors','waterfront','view',\n",
    "# 'condition','grade','sqft_above','sqft_basement','yr_built','yr_renovated',\n",
    "# 'zipcode','lat','long','sqft_living15','sqft_lot15'\n",
    "\n",
    "# If you already have a training subset, put it in df_train directly.\n",
    "# Otherwise, split and use the training portion per instructions.\n",
    "df_train, df_test = train_test_split(df_full, test_size=0.2, random_state=42)\n",
    "print('Train shape:', df_train.shape, ' Test shape:', df_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7862df46",
   "metadata": {},
   "source": [
    "\n",
    "## Problem 1 — Interactions\n",
    "**(A)** Select one of your four continuous predictors and one of your three categorical predictors. Fit a multiple linear regression for **price** on those two variables. Report the fitted coefficients.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92c9b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ==========================\n",
    "# Problem 1A\n",
    "# ==========================\n",
    "\n",
    "# Choose ONE continuous and ONE categorical predictor here.\n",
    "# You can change these if your chosen set is different.\n",
    "continuous_var = 'sqft_living'   # example continuous predictor\n",
    "categorical_var = 'waterfront'   # example categorical (0/1)\n",
    "\n",
    "# Ensure categorical is treated as category\n",
    "df_train[categorical_var] = df_train[categorical_var].astype('category')\n",
    "\n",
    "# Model without interaction\n",
    "formula_no_inter = f'price ~ {continuous_var} + C({categorical_var})'\n",
    "model_no_inter = smf.ols(formula=formula_no_inter, data=df_train).fit()\n",
    "print('Model without interaction:')\n",
    "print(model_no_inter.summary())\n",
    "\n",
    "print('\\nFitted coefficients (no interaction):')\n",
    "print(model_no_inter.params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2afaea2b",
   "metadata": {},
   "source": [
    "\n",
    "**(B)** Now add an interaction term to that model. Compare the coefficients and explain the meaning of the interaction term in context. Do you think it's useful here?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3369b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ==========================\n",
    "# Problem 1B\n",
    "# ==========================\n",
    "formula_inter = f'price ~ {continuous_var} * C({categorical_var})'\n",
    "model_inter = smf.ols(formula=formula_inter, data=df_train).fit()\n",
    "print('Model with interaction:')\n",
    "print(model_inter.summary())\n",
    "\n",
    "print('\\nCoefficient comparison:')\n",
    "coef_compare = pd.DataFrame({\n",
    "    'no_interaction': model_no_inter.params.reindex(model_inter.params.index, fill_value=np.nan),\n",
    "    'with_interaction': model_inter.params\n",
    "})\n",
    "print(coef_compare)\n",
    "\n",
    "print('\\nInterpretation helper:')\n",
    "print(f\"\"\"\n",
    "- The interaction term modifies the slope of {continuous_var} for different levels of {categorical_var}.\n",
    "- If the interaction coefficient is positive, the effect (slope) of {continuous_var} on price is larger for the indicated level of {categorical_var}, and vice versa.\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7e4483",
   "metadata": {},
   "source": [
    "\n",
    "**(C)** Make a scatterplot of **price** against the continuous predictor and add **two regression lines** (one per level of the categorical variable) from the interaction model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c400c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ==========================\n",
    "# Problem 1C\n",
    "# ==========================\n",
    "levels = df_train[categorical_var].cat.categories\n",
    "\n",
    "plt.figure()\n",
    "for lvl in levels:\n",
    "    mask = df_train[categorical_var] == lvl\n",
    "    plt.scatter(df_train.loc[mask, continuous_var], df_train.loc[mask, 'price'], alpha=0.4, label=f'{categorical_var}={lvl}')\n",
    "    \n",
    "# Compute lines using model_inter params:\n",
    "# price = b0 + b1*x + b2*I(lvl) + b3*x*I(lvl)\n",
    "x_grid = np.linspace(df_train[continuous_var].min(), df_train[continuous_var].max(), 100)\n",
    "\n",
    "params = model_inter.params\n",
    "b0 = params.get('Intercept', 0.0)\n",
    "b1 = params.get(continuous_var, 0.0)\n",
    "# For categorical treatment coding, level names appear as C(var)[T.level]\n",
    "for lvl in levels[1:]:  # reference is the first category; others get T.lvl\n",
    "    b_cat = params.get(f'C({categorical_var})[T.{lvl}]', 0.0)\n",
    "    b_int = params.get(f'{continuous_var}:C({categorical_var})[T.{lvl}]', 0.0)\n",
    "    y = b0 + b1*x_grid + b_cat + b_int*x_grid\n",
    "    plt.plot(x_grid, y, label=f'Fit line: {categorical_var}={lvl}')\n",
    "# Add line for reference level (no cat increment, no interaction increment)\n",
    "y_ref = b0 + b1*x_grid\n",
    "plt.plot(x_grid, y_ref, label=f'Fit line: {categorical_var}={levels[0]}')\n",
    "\n",
    "plt.xlabel(continuous_var)\n",
    "plt.ylabel('price')\n",
    "plt.legend()\n",
    "plt.title('Price vs. ' + continuous_var + ' with interaction-based lines')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b849d15",
   "metadata": {},
   "source": [
    "\n",
    "## Problem 2 — Log Transforms\n",
    "**(A)** Decide if it makes sense to log-transform the response (**price**). Explain with graphs or statistics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f84cb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ==========================\n",
    "# Problem 2A\n",
    "# ==========================\n",
    "# Visualize price vs. log(price)\n",
    "fig = plt.figure()\n",
    "plt.hist(df_train['price'].dropna(), bins=50)\n",
    "plt.title('Histogram of price')\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.hist(np.log(df_train['price'].dropna()), bins=50)\n",
    "plt.title('Histogram of log(price)')\n",
    "plt.show()\n",
    "\n",
    "# Skewness/kurtosis\n",
    "print('Skewness price:', stats.skew(df_train['price'].dropna()))\n",
    "print('Skewness log(price):', stats.skew(np.log(df_train['price'].dropna())))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26efccf2",
   "metadata": {},
   "source": [
    "\n",
    "**(B)** Consider each of your **four chosen numerical predictors**. Is a log-transform reasonable for any? Explain.\n",
    "(The cell below provides a helper to inspect skew and simple scatterplots. Update the list to your four numerical predictors.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a64fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ==========================\n",
    "# Problem 2B\n",
    "# ==========================\n",
    "num_predictors = ['sqft_living', 'sqft_lot', 'bedrooms', 'bathrooms']  # <-- change to your chosen 4\n",
    "\n",
    "for col in num_predictors:\n",
    "    series = df_train[col].dropna()\n",
    "    fig = plt.figure()\n",
    "    plt.hist(series, bins=50)\n",
    "    plt.title(f'Histogram of {col}')\n",
    "    plt.show()\n",
    "    \n",
    "    if (series > 0).all():\n",
    "        fig = plt.figure()\n",
    "        plt.hist(np.log(series), bins=50)\n",
    "        plt.title(f'Histogram of log({col})')\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(f'Skipping log({col}) histogram because of non-positive values.')\n",
    "    \n",
    "    # Quick scatter vs price\n",
    "    fig = plt.figure()\n",
    "    plt.scatter(df_train[col], df_train['price'], alpha=0.3)\n",
    "    plt.xlabel(col); plt.ylabel('price'); plt.title(f'price vs {col}')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e4cece",
   "metadata": {},
   "source": [
    "\n",
    "**(C)** Fit two multiple linear regressions for price based on **all seven** of your predictors (continuous + categorical).\n",
    "- Model 1: untransformed variables  \n",
    "- Model 2: apply the transformations you chose in (A) and (B)\n",
    "Compare R² and RMSE. Which fits better?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc06e433",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ==========================\n",
    "# Problem 2C\n",
    "# ==========================\n",
    "# Choose your 7 predictors here. Example selection:\n",
    "cont_vars = ['sqft_living', 'sqft_lot', 'bedrooms', 'bathrooms']    # 4 continuous\n",
    "cat_vars  = ['view', 'condition', 'grade']                           # 3 categorical (treated as categorical below)\n",
    "\n",
    "# Ensure categorical dtype\n",
    "for c in cat_vars:\n",
    "    df_train[c] = df_train[c].astype('category')\n",
    "\n",
    "# ---- Model 1: Untransformed price & predictors ----\n",
    "formula1 = 'price ~ ' + ' + '.join(cont_vars + [f'C({c})' for c in cat_vars])\n",
    "m1 = smf.ols(formula=formula1, data=df_train).fit()\n",
    "print('Model 1 (untransformed) summary:')\n",
    "print(m1.summary())\n",
    "\n",
    "# RMSE on train\n",
    "rmse1 = mean_squared_error(df_train['price'], m1.fittedvalues, squared=False)\n",
    "print('Train RMSE (Model 1):', rmse1)\n",
    "\n",
    "# ---- Model 2: Transformed based on choices ----\n",
    "# Example choices (adjust as needed):\n",
    "# - Use log(price)\n",
    "# - log(sqft_living), log(sqft_lot) if positive\n",
    "df_train = df_train.copy()\n",
    "df_train['log_price'] = np.log(df_train['price'])\n",
    "\n",
    "def safe_log(s):\n",
    "    return np.log(s.clip(lower=1))  # avoid log(0)\n",
    "df_train['log_sqft_living'] = safe_log(df_train['sqft_living'])\n",
    "df_train['log_sqft_lot']    = safe_log(df_train['sqft_lot'])\n",
    "\n",
    "# Keep bedrooms, bathrooms untransformed for this example\n",
    "formula2 = 'log_price ~ log_sqft_living + log_sqft_lot + bedrooms + bathrooms + ' + ' + '.join([f'C({c})' for c in cat_vars])\n",
    "m2 = smf.ols(formula=formula2, data=df_train).fit()\n",
    "print('\\nModel 2 (transformed) summary:')\n",
    "print(m2.summary())\n",
    "\n",
    "# Compare on train (RMSE for log-price back on price scale via exp of fitted for rough comparison)\n",
    "pred_log = m2.fittedvalues\n",
    "pred_price_m2 = np.exp(pred_log)\n",
    "rmse2 = mean_squared_error(df_train['price'], pred_price_m2, squared=False)\n",
    "print('Train RMSE (Model 2, back-transformed):', rmse2)\n",
    "\n",
    "print('\\nComparison:')\n",
    "print(pd.DataFrame({'R2':[m1.rsquared, m2.rsquared], 'RMSE':[rmse1, rmse2]}, index=['Model 1 (price)','Model 2 (log-price)']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa2abd77",
   "metadata": {},
   "source": [
    "\n",
    "**(D)** Make a **residual plot** for the model with transformed variables. Comment on the fit.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cfe7a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ==========================\n",
    "# Problem 2D\n",
    "# ==========================\n",
    "resid = df_train['log_price'] - m2.fittedvalues\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(m2.fittedvalues, resid, alpha=0.3)\n",
    "plt.axhline(0, linestyle='--')\n",
    "plt.xlabel('Fitted (log-price)')\n",
    "plt.ylabel('Residuals')\n",
    "plt.title('Residual plot — transformed model')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de99d66",
   "metadata": {},
   "source": [
    "\n",
    "## Problem 3 — Feature Engineering (Location)\n",
    "**(A)** Scatterplot of **longitude vs latitude** colored by price (or log price). Explain what it shows.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de6167d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ==========================\n",
    "# Problem 3A\n",
    "# ==========================\n",
    "plt.figure()\n",
    "plt.scatter(df_train['long'], df_train['lat'], c=np.log(df_train['price']), alpha=0.4)\n",
    "plt.xlabel('longitude'); plt.ylabel('latitude')\n",
    "plt.title('Longitude vs Latitude (color = log(price))')\n",
    "plt.colorbar(label='log(price)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e3a8eaa",
   "metadata": {},
   "source": [
    "\n",
    "**(B)** Create a **radial distance** feature from the point with maximum prices (approx): latitude 47.63, longitude -122.22.\n",
    "Use: \\( r = \\sqrt{(x - p)^2 + (y - q)^2} \\) where \\((x,y)=(\\text{lat},\\text{long})\\), \\((p,q)=(47.63, -122.22)\\).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc042b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ==========================\n",
    "# Problem 3B\n",
    "# ==========================\n",
    "p_lat, p_long = 47.63, -122.22\n",
    "df_train['r'] = np.sqrt((df_train['lat'] - p_lat)**2 + (df_train['long'] - p_long)**2)\n",
    "print(df_train['r'].describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b406f08",
   "metadata": {},
   "source": [
    "\n",
    "**(C)** Fit a simple linear regression for **price (or log price)** on `r`. Plot the scatter with regression line. Comment on usefulness.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b81ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ==========================\n",
    "# Problem 3C\n",
    "# ==========================\n",
    "# We'll use log-price for stability\n",
    "model_r = smf.ols('log_price ~ r', data=df_train).fit()\n",
    "print(model_r.summary())\n",
    "\n",
    "# Scatter + line\n",
    "plt.figure()\n",
    "plt.scatter(df_train['r'], df_train['log_price'], alpha=0.3)\n",
    "xg = np.linspace(df_train['r'].min(), df_train['r'].max(), 200)\n",
    "yg = model_r.params['Intercept'] + model_r.params['r'] * xg\n",
    "plt.plot(xg, yg)\n",
    "plt.xlabel('r (radial distance)')\n",
    "plt.ylabel('log(price)')\n",
    "plt.title('log(price) vs r with fitted line')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d9a3a6",
   "metadata": {},
   "source": [
    "\n",
    "## Problem 4 — Standardization & Model Building\n",
    "**Goal:** Build the best possible model using your selected predictors (the seven from before), the engineered `r`, any interactions you wish, and your chosen transformations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25044a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ==========================\n",
    "# Problem 4A — Choose Predictors & Build DataFrame\n",
    "# ==========================\n",
    "# You can adjust this list as desired.\n",
    "target = 'log_price'  # or 'price'\n",
    "\n",
    "# Start with earlier chosen variables and add engineered r\n",
    "selected_cont = ['log_sqft_living', 'log_sqft_lot', 'bedrooms', 'bathrooms', 'r']  # transformed where chosen\n",
    "selected_cat  = ['view', 'condition', 'grade']\n",
    "\n",
    "# Optionally add an interaction term name to include later (sklearn will handle via feature crosses if we create them)\n",
    "# For demonstration, we'll add an interaction between log_sqft_living and grade (treated categorically via one-hot).\n",
    "interaction_pairs = [('log_sqft_living', 'grade')]\n",
    "\n",
    "# Make a working frame with required columns\n",
    "needed = ['price','log_price','lat','long','r','log_sqft_living','log_sqft_lot','bedrooms','bathrooms','view','condition','grade']\n",
    "work = df_train[needed].dropna().copy()\n",
    "\n",
    "print('Working data shape:', work.shape)\n",
    "work.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13fd4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ==========================\n",
    "# Problem 4 — Standardized Linear Model (sklearn)\n",
    "# ==========================\n",
    "# We'll create explicit interaction features by multiplying columns AFTER encoding.\n",
    "# Pipeline:\n",
    "#   - OneHotEncode categorical\n",
    "#   - Standardize numeric\n",
    "#   - LinearRegression\n",
    "\n",
    "numeric_features = ['log_sqft_living', 'log_sqft_lot', 'bedrooms', 'bathrooms', 'r']\n",
    "categorical_features = ['view', 'condition', 'grade']\n",
    "\n",
    "pre = ColumnTransformer([\n",
    "    ('num', StandardScaler(), numeric_features),\n",
    "    ('cat', OneHotEncoder(drop='first', handle_unknown='ignore'), categorical_features),\n",
    "])\n",
    "\n",
    "linreg = LinearRegression()\n",
    "\n",
    "pipe = Pipeline([('pre', pre), ('linreg', linreg)])\n",
    "\n",
    "X = work[numeric_features + categorical_features].copy()\n",
    "y = work[target].copy()\n",
    "\n",
    "# Fit baseline (no custom interaction terms yet)\n",
    "pipe.fit(X, y)\n",
    "y_hat = pipe.predict(X)\n",
    "\n",
    "print('Sklearn baseline (standardized)')\n",
    "print('R^2:', r2_score(y, y_hat))\n",
    "print('RMSE:', mean_squared_error(y, y_hat, squared=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3560e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ==========================\n",
    "# Problem 4 — Add an example interaction (log_sqft_living x grade)\n",
    "# ==========================\n",
    "# Create interaction columns manually on X with one-hot of grade.\n",
    "X2 = X.copy()\n",
    "# One-hot grade for manual interactions\n",
    "grade_dummies = pd.get_dummies(X2['grade'], prefix='grade', drop_first=True)\n",
    "for col in grade_dummies.columns:\n",
    "    X2[f'log_sqft_living_x_{col}'] = X2['log_sqft_living'] * grade_dummies[col]\n",
    "\n",
    "# Update preprocessor to pass through these extra numeric interaction columns\n",
    "extra_numeric = [c for c in X2.columns if c.startswith('log_sqft_living_x_')]\n",
    "numeric_all = ['log_sqft_living', 'log_sqft_lot', 'bedrooms', 'bathrooms', 'r'] + extra_numeric\n",
    "\n",
    "pre2 = ColumnTransformer([\n",
    "    ('num', StandardScaler(), numeric_all),\n",
    "    ('cat', OneHotEncoder(drop='first', handle_unknown='ignore'), categorical_features),\n",
    "])\n",
    "\n",
    "pipe2 = Pipeline([('pre', pre2), ('linreg', LinearRegression())])\n",
    "pipe2.fit(X2, y)\n",
    "y2_hat = pipe2.predict(X2)\n",
    "\n",
    "print('Sklearn model with interaction (log_sqft_living x grade)')\n",
    "print('R^2:', r2_score(y, y2_hat))\n",
    "print('RMSE:', mean_squared_error(y, y2_hat, squared=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4020f6",
   "metadata": {},
   "source": [
    "\n",
    "### Notes for your write-up\n",
    "- Explain your variable choices and why each transformation was used.\n",
    "- Interpret the interaction term(s) in the context of house prices.\n",
    "- Comment on diagnostics (residuals, heteroscedasticity, nonlinearity).\n",
    "- State which model you prefer based on R², RMSE, and visual checks.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
